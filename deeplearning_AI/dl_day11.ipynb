{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\poeun\\anaconda3\\envs\\tf2.4\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 가장 높은 1000개의 단어만 추출\n",
    "(xtrain, ytrain), (xtest, ytest) = reuters.load_data(num_words=1000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "xtrain.shape # (8982,)\n",
    "print(xtrain[0]) # 첫번째 뉴스기사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category=np.max(ytrain)+1\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 수를 100개로 통일 (모자란 부분은 0으로 채워짐. 남으면 제거)\n",
    "xtrain=sequence.pad_sequences(xtrain, maxlen=100)\n",
    "xtest=sequence.pad_sequences(xtest, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=to_categorical(ytrain)\n",
    "ytest=to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설정\n",
    "# 임베딩 계층 : 입력된 데이터를 전달 받아서 임베딩 벡터로 변환\n",
    "# Embedding(단어종류개수, 임베딩벡터차원, 문서최대길이)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=10, input_length=100))\n",
    "# 문서에 등장할 수 있는 단어의 종류가 1000가지 있음\n",
    "# 1000차원 단어 벡터 -> 임베딩 -> 10차원 단어 벡터 공간\n",
    "\n",
    "# input_length=100 : 모든 문서에 등장하는 단어 시퀀스 길이가 100이다.\n",
    "\n",
    "\n",
    "model.add(LSTM(100, activation = \"tanh\"))\n",
    "model.add(Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "90/90 [==============================] - 25s 96ms/step - loss: 2.9692 - accuracy: 0.3298 - val_loss: 2.4227 - val_accuracy: 0.3620\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 6s 71ms/step - loss: 2.3968 - accuracy: 0.3576 - val_loss: 2.4133 - val_accuracy: 0.3620\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 2.3805 - accuracy: 0.3581 - val_loss: 2.1585 - val_accuracy: 0.4715\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 6s 63ms/step - loss: 2.0946 - accuracy: 0.4725 - val_loss: 1.9559 - val_accuracy: 0.4920\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.9063 - accuracy: 0.5088 - val_loss: 1.8258 - val_accuracy: 0.5365\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.8139 - accuracy: 0.5229 - val_loss: 1.7708 - val_accuracy: 0.5392\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 1.7170 - accuracy: 0.5529 - val_loss: 1.8668 - val_accuracy: 0.5147\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.7900 - accuracy: 0.5256 - val_loss: 1.7339 - val_accuracy: 0.5539\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.6666 - accuracy: 0.5638 - val_loss: 1.7267 - val_accuracy: 0.5512\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 6s 66ms/step - loss: 1.6537 - accuracy: 0.5705 - val_loss: 1.7161 - val_accuracy: 0.5628\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 6s 65ms/step - loss: 1.6522 - accuracy: 0.5689 - val_loss: 1.6866 - val_accuracy: 0.5659\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 5s 60ms/step - loss: 1.5962 - accuracy: 0.5880 - val_loss: 1.6584 - val_accuracy: 0.5819\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 1.5273 - accuracy: 0.6045 - val_loss: 1.6299 - val_accuracy: 0.5859\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 6s 66ms/step - loss: 1.5416 - accuracy: 0.6015 - val_loss: 1.6074 - val_accuracy: 0.5917\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 6s 68ms/step - loss: 1.4934 - accuracy: 0.6096 - val_loss: 1.5980 - val_accuracy: 0.5846\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 6s 67ms/step - loss: 1.4695 - accuracy: 0.6118 - val_loss: 1.5519 - val_accuracy: 0.6060\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 6s 69ms/step - loss: 1.4128 - accuracy: 0.6294 - val_loss: 1.5277 - val_accuracy: 0.6122\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 6s 62ms/step - loss: 1.3945 - accuracy: 0.6398 - val_loss: 1.4678 - val_accuracy: 0.6296\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 5s 58ms/step - loss: 1.3260 - accuracy: 0.6548 - val_loss: 1.4304 - val_accuracy: 0.6358\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 5s 56ms/step - loss: 1.3122 - accuracy: 0.6627 - val_loss: 1.4238 - val_accuracy: 0.6313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a058089898>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain,\n",
    "          batch_size=100, epochs=20,\n",
    "          validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 10)           10000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 46)                4646      \n",
      "=================================================================\n",
      "Total params: 59,046\n",
      "Trainable params: 59,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc67a1954fc8719de0f41a445e21b857837fa5db3f7fb7e297696149c4e3d566"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tf2.4': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
